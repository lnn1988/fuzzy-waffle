# 卡夫卡:一种分布式的日志处理信息系统

### 摘要

日志处理已成为互联网公司数据管道中的重要组成部分。 我们介绍Kafka，一个分布式消息传递系统，我们开发该系统是为了以低延迟收集和传递大量日志数据。 我们的系统结合了现有的日志聚合器和消息传递系统的想法，适用于脱机和联机环境。 我们在Kafka中做出了许多非常规但实用的设计选择，以使我们的系统高效且可扩展。 与两种流行的消息传递系统相比，实验结果表明Kafka具有更卓越的性能。 我们已经在生产中使用Kafka已有一段时间了，它每天要处理数百GB的新数据。

### Keywords

消息传递，分布式，日志处理，吞吐量，联机

## 1. 简介

所有大规模的互联网公司都会生成大量的“日志”数据，通常包括：

1. 登录、浏览、点击、喜欢、共享、评论或查询类似的用户活动行为事件
2. 操作指标，比如服务调用堆栈、调用延迟、错误或者其他系统指标如 CPU、内存、网络或者硬盘使用量

日志数据已经变成了跟踪用户参与度、系统指标的关键组成部分。但是，互联网的最新趋势是使活动数据通过生产数据管道直接用于站点功能。包括：

1. 搜索相关性
2. 通过主题流行性或者共现程度提供的建议
3. 广告目标人群定位
4. 防止滥用行为，比如垃圾邮件或者爬虫过滤
5. 新闻提要功能以供用户的状态更新给他的朋友或者相关的人

日志数据的这种实时生产使用给数据系统带来了新的挑战，因为其数据量比“实际”数据大几个数量级。 例如，搜索，推荐和广告经常需要计算精确的点击率，这不仅会为每个用户点击生成日志记录，还会为每个页面上数十个未被点击的项目生成日志记录。 每天，中国移动收集5–8 TB的电话记录[11]，而Facebook收集近6 TB的各种用户活动事件[12]。
许多用于处理此类数据的早期系统都依靠物理方式将日志文件从生产服务器上拷贝下来进行分析。 近年来，已经建立了几种专门的分布式日志聚合器，包括Facebook的Scribe [6]，Yahoo的Data Highway [4]和Cloudera的Flume [3]。 这些系统主要用于收集日志数据并将其加载到数据仓库或Hadoop [8]中以供离线使用。 在LinkedIn（一个社交网站）上，我们发现，除了传统的离线分析之外，我们还需要以不超过几秒钟的延迟来支持上述大多数实时应用程序。

我们建立了一种用于日志处理的新型消息传递系统，称为Kafka [18]，该系统结合了传统日志聚合器和消息传递系统的优势。 一方面，Kafka是分布式且可扩展的，并提供高吞吐量。 另一方面，Kafka提供类似于消息传递系统的API，并允许应用程序实时使用日志事件。 Kafka已开源，并已在LinkedIn上成功用于生产中超过6个月。 因为我们可以利用单个软件来在线和离线使用所有类型的日志数据，所以它极大地简化了我们的基础架构。 本文的其余部分安排如下。 我们将在第2节中回顾传统的消息传递系统和日志聚合器。在第3节中，我们描述Kafka的体系结构及其关键设计原则。 我们将在第4节中介绍在LinkedIn上部署Kafka的情况，并在第5节中介绍Kafka的性能结果。在第6节中，我们讨论未来的工作并进行总结。

## 2. 相关工作

传统的企业消息传递系统[1] [7] [15] [17]已经存在了很长时间，并且经常作为处理异步数据流的事件总线发挥关键作用。但是，由于某些原因，它们往往不适合日志处理。首先，企业系统提供的功能不匹配。这些系统通常专注于提供丰富的交付保证。例如，IBM Websphere MQ [7]具有事务支持，允许应用程序原子地将消息插入多个队列。 JMS [14]规范允许在使用后确认每个单独的消息，这可能会导致混乱。这样的交付保证对于收集日志数据通常是过度的。例如，偶尔失去一些综合浏览量事件肯定不是致命的。这些不需要的功能往往会增加API和这些系统的基础实现的复杂性。其次，许多系统没有像其主要设计约束那样专注于吞吐量。例如，JMS没有API允许生产者将多个消息显式批处理为单个请求。这意味着每个消息都需要完整的TCP / IP往返，这对于这个领域的吞吐量要求是不可行的。第三，这些系统在分布式支持方面薄弱。没有简单的方法可以在多台计算机上进行分区和存储消息。最后，许多消息传递系统假定消息被收集到之后将立即消耗掉，因此未消耗消息的队列总是很小。如果允许累积消息，对于脱机使用的情形，它们的性能将大大降低，例如，数据仓库应用程序，它们会定期进行大负载而不是连续使用。

在过去的几年中，已经建立了许多专业的日志聚合器。 Facebook使用名为Scribe的系统。每个前端计算机都可以通过套接字将日志数据发送到一组Scribe计算机。每台Scribe机器都会汇总日志条目，并定期将它们转储到HDFS [9]或NFS设备。雅虎的data highway项目具有类似的数据流。一组计算机聚合来自客户端的事件并推出“分钟”文件，然后将其添加到HDFS。 Flume是由Cloudera开发的相对较新的日志聚合器。它支持可扩展的“管道”和“接收器”，使得流式日志数据非常灵活，并且融合了分布式支持。但是，大多数这些系统是为脱机消费日志数据而构建的，并且经常不必要地向使用者公开实现细节（例如“分钟文件”）。此外，它们中的大多数使用“push”模型，其中broker将数据转发给消费者。在LinkedIn，我们发现“pull”模型更适合我们的应用程序，因为每个消费者都可以以其可以维持的最大速率检索消息，并避免被推送速度超出其处理的能力从而导致消息淹没。pull模型还可以轻松地回放消费者，我们将在第3.2节的末尾讨论这种好处。最近，雅虎！研究开发了一种新的分布式发布/订阅系统，称为HedWig [13]。 HedWig具有高度的可扩展性和可用性，并提供强大的耐用性保证。但是，它主要用于存储数据存储的提交日志。

## 3. Kafka 架构以及设计原理

由于现有系统的限制，我们开发了一种新的基于消息的日志聚合器Kafka。 我们首先介绍Kafka中的基本概念。 主题定义特定类型的消息流。 生产者可以将消息发布到主题。 然后，已发布的消息将存储在一组称为broker的服务器上。 消费者可以订阅来自broker的一个或多个主题，并通过从broker获取数据来消费订阅的消息。
消息从概念上讲很简单，我们试图使Kafka API同样简单以反映这一点。 我们没有介绍确切的API，而是提供了一些示例代码来说明如何使用API。 生产者的示例代码如下。 一条消息被定义为仅包含字节的有效负载。 用户可以选择喜欢的序列化方法来编码消息。 为了提高效率，生产者可以在单个发布请求中发送一组消息。

**Sample producer code:** 

```java
producer = new Producer(…); 
message = new Message(“test message str”.getBytes()); 
set = new MessageSet(message); 
producer.send(“topic1”, set);
```

为了订阅主题，消费者首先为该主题创建一个或多个消息流。 发布给该主题的消息将平均分配到这些子流中。 有关Kafka如何分发消息的详细信息，将在第3.2节中介绍。 每个消息流在正在生成的连续消息流上提供迭代器接口。 然后，使用者遍历流中的每个消息并处理消息的有效负载。 与传统的迭代器不同，消息流迭代器永远不会终止。 如果当前没有更多消息可使用，则迭代器将阻塞，直到将新消息发布到该主题为止。 我们既支持点对点传递模型（其中多个使用者共同使用一个主题中所有消息的一个副本），也支持发布/订阅模型（其中多个使用者各自检索其自己的主题副本）。

**Sample consumer code:**

```java
streams[] = Consumer.createMessageStreams(“topic1”, 1)
for (message : streams[0]) 
{ 
	bytes = message.payload(); 
	// do something with the bytes 
}
```

Kafka的总体体系结构如图1所示。由于Kafka实际上是分布式的，因此Kafka集群通常由多个broker组成。 为了平衡负载，一个主题分为多个分区，每个代理存储一个或多个这些分区。 多个生产者和消费者可以同时发布和检索消息。 在第3.1节中，我们描述了代理上单个分区的布局以及我们选择的一些设计选择，以使访问分区更加有效。 在3.2节中，我们描述了生产者和消费者如何在分布式环境中与多个broker进行交互。 我们将在第3.3节中讨论Kafka的交付保证。

![截屏2019-10-22下午3.13.30](https://tva1.sinaimg.cn/large/006y8mN6ly1g86zzejsihj309g076754.jpg)



### 3.1 一个分区上的效率